<!DOCTYPE html>
<html>
  <head>
    <link href="css/reset.css" rel="stylesheet" />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1024" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <link rel="shortcut icon" href="css/favicon.png" />
    <link rel="apple-touch-icon" href="css/apple-touch-icon.png" />
    <!-- Code Prettifier: -->
<link href="css/highlight.css" type="text/css" rel="stylesheet" />
<script type="text/javascript" src="js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

    <link href="css/style.css" rel="stylesheet" />
<link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,800italic,300,400,800' rel='stylesheet' type='text/css'>    


  </head>

  <body>
  <div class="fallback-message">
  <p>Your browser <b>doesn't support the features required</b> by impress.js, so you are presented with a simplified version of this presentation.</p>
  <p>For the best experience please use the latest <b>Chrome</b>, <b>Safari</b> or <b>Firefox</b> browser.</p>
  </div>
    <div id="impress">
    <div class='step' >
    
<h1>Cascalog</h1>

<h2>Logic Programming Over Hadoop</h2>

<p>Alex Robbins &nbsp;&nbsp;&nbsp;&nbsp; <img src="images/factual-high-res.png" alt="factual-logo" title="Factual"></p>
</div>
      <div class='step' >
    
<h1>What can Cascalog do for me?</h1>

<!--- Notes:
This is meant to be a practical talk about Cascalog. Although it is certainly
some cool tech, we each already have a list of things we'd like to check out
that is longer than we'll ever get to. It is my hope that this talk will help
you decide whether or not Cascalog is worth the time it'll take you to
understand it.
--->
</div>
      <div class='step' >
    
<h1>What problem does it solve?</h1>

<!--- Notes:
Cascalog provides a way to describe and execute distributed computing jobs.
If you have a task that can be parallelized and is taking too long, Cascalog
can help. Cascalog allows you to easily break a task down into chunks, and
pass those chunks around a computing cluster of dozens or hundreds of servers.
--->
</div>
      <div class='step' >
    
<h1>Who else solves this problem?</h1>

<!--- Notes:
Cascalog is not the only distributed computing framework. Actually, it is built
on top of one of its biggest competitors, Hadoop. Other packages currently
solving this problem include Pig, Hive and Riak, just to name a few. The different
packages embrace different abstractions, as well as different levels of
abstraction.
--->
</div>
      <div class='step' >
    
<h1>Hadoop</h1>

<p>Perfect for anyone who thinks in Map/Reduce, and likes typing.</p>

<!--- Notes:
Hadoop is the current dominant force in the world of distributed computing.
Most of its competitors are built on top of it, and reuse pieces of it, such as
HDFS, Hadoop's distributed file system. Hadoop provides low level control over your
jobs, with the normal tradeoffs for low level programming. Writing compute jobs
in hadoop requires a fair amount of boilerplate, with even very simple tasks
taking more than 50 lines of code. At the same time, Hadoop works.
--->
</div>
      <div class='step' >
    <pre><code class='prettyprint Java'>package org.myorg;

import java.io.IOException;
import java.util.*;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

public class WordCount {

  public static class Map extends Mapper<LongWritable, Text, Text, IntWritable> {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
      String line = value.toString();
      StringTokenizer tokenizer = new StringTokenizer(line);
      while (tokenizer.hasMoreTokens()) {
        word.set(tokenizer.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class Reduce extends Reducer<Text, IntWritable, Text, IntWritable> {

    public void reduce(Text key, Iterable<IntWritable> values, Context context)
      throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      context.write(key, new IntWritable(sum));
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = new Job(conf, "wordcount");
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    job.setMapperClass(Map.class);
    job.setReducerClass(Reduce.class);
    job.setInputFormatClass(TextInputFormat.class);
    job.setOutputFormatClass(TextOutputFormat.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    job.waitForCompletion(true);
  }

}

// http://wiki.apache.org/hadoop/WordCount
</code></pre></div>
      <div class='step' >
    
<h1>Pig</h1>

<p>Because everyone wants to learn another programming language.</p>

<!--- Notes:
Disclaimer: I've never used Pig myself.
Pig allows you to write commands in pig-latin that are run over the cluster. If you
want to add functionality to a Pig query, you write a "User Defined Function."
As your needs get more and more specialized, you end up writing many UDFs, all
in Java.
--->
</div>
      <div class='step' >
    <pre><code class='prettyprint '>input_lines = LOAD '/tmp/my-copy-of-all-pages-on-internet' AS (line:chararray);

-- Extract words from each line and put them into a pig bag
-- datatype, then flatten the bag to get one word on each row
words = FOREACH input_lines GENERATE FLATTEN(TOKENIZE(line)) AS word;

-- filter out any words that are just white spaces
filtered_words = FILTER words BY word MATCHES '\\w+';

-- create a group for each word
word_groups = GROUP filtered_words BY word;

-- count the entries in each group
word_count = FOREACH word_groups GENERATE COUNT(filtered_words) AS count, group AS word;

-- order the records by count
ordered_word_count = ORDER word_count BY count DESC;
STORE ordered_word_count INTO '/tmp/number-of-words-on-internet';

-- http://en.wikipedia.org/wiki/Pig_(programming_tool)
</code></pre></div>
      <div class='step' >
    
<h1>Hive</h1>

<p>A great fit for people who love SQL, and wish they could use it for everything.</p>
</div>
      <div class='step' >
    <pre><code class='prettyprint '>CREATE TABLE docs(contents STRING);
FROM

(MAP docs.contents USING 'tokenizer_script' AS word, cnt
FROM docs
CLUSTER BY word) map_output

REDUCE map_output.word, map_output.cnt USING 'count_script' AS word, cnt;

;; Note that you have to provide your own tokenizer and counter, in whatever language you want.
</code></pre></div>
      <div class='step' >
    
<h1>Cascalog</h1>

<p>The power of logic programming and Clojure, combined with a lot of magic.</p>

<!--- Notes:
Obviously, we'll be talking about Cascalog for the rest of the talk, so I don't
want to give it all away now. The high level strengths and weaknesses are:
Strengths: concise, easily extensible, Clojure!
Weaknesses: lots of magic, forces a restricted subset of clojure (no lambdas),
  cryptic error messages
--->
</div>
      <div class='step' >
    <pre><code class='prettyprint '>(ns cascalog-class.core
  (:require [cascalog.api :refer :all]
            [cascalog.ops :as c]))

(defmapcatop split
  "Accepts a sentence 1-tuple, splits that sentence on whitespace, and
  emits a single 1-tuple for each word."
  [^String sentence]
  (.split sentence "\\s+"))

(def -main
  "Accepts a generator of lines of text and returns a subquery that
  generates a count for each word in the text sample."
  (?<- (stdout)
    [?word ?count]
    ((hfs-textline "input-dir") ?textline)
    (split ?textline :> ?word)
    (c/count ?count)))

;; https://github.com/sritchie/cascalog-class/blob/master/src/cascalog_class/core.clj
</code></pre></div>
      <div class='step' >
    <pre><code class='prettyprint Left-java-code'>package org.myorg;

import java.io.IOException;
import java.util.*;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

public class WordCount {

  public static class Map extends Mapper<LongWritable, Text, Text, IntWritable> {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(LongWritable key, Text value, Context context)
      throws IOException, InterruptedException {
      String line = value.toString();
      StringTokenizer tokenizer = new StringTokenizer(line);
      while (tokenizer.hasMoreTokens()) {
        word.set(tokenizer.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class Reduce extends Reducer<Text, IntWritable, Text, IntWritable> {

    public void reduce(Text key, Iterable<IntWritable> values, Context context)
      throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      context.write(key, new IntWritable(sum));
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = new Job(conf, "wordcount");
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    job.setMapperClass(Map.class);
    job.setReducerClass(Reduce.class);
    job.setInputFormatClass(TextInputFormat.class);
    job.setOutputFormatClass(TextOutputFormat.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    job.waitForCompletion(true);
  }

}

// http://wiki.apache.org/hadoop/WordCount
</code></pre><pre><code class='prettyprint Right-clojure-code'>(ns cascalog-class.core
  (:require [cascalog.api :refer :all]
            [cascalog.ops :as c]))

(defmapcatop split
  [^String sentence]
  (.split sentence "\\s+"))

(def -main
  (?<- (stdout)
    [?word ?count]
    ((hfs-textline "input-dir") ?textline)
    (split ?textline :> ?word)
    (c/count ?count)))

;; https://github.com/sritchie/cascalog-class/blob/master/src/cascalog_class/core.clj
</code></pre>
<div style="clear: both">&nbsp;</div>

<p>Cascalog: 311 characters</p>

<p>Hadoop:  1950 characters (6x more)</p>
</div>
      <div class='step' >
    
<h1>What is Cascalog?</h1>

<p><strong>Casca</strong>ding + Data<strong>log</strong> = <strong>Cascalog</strong></p>

<!--- Notes:
Unfortunately, over the next several slides I'll be defining terms by using other
terms that you likely don't know. However, I promise to cover those terms in
even later slides.

In this case, the question is, "What is Cascalog?" The answer is, "Cascalog is a
combination of Cascading and Datalog." An answer that is technically correct
(the best kind of correct), but useless to most of you.
--->
</div>
      <div class='step' >
    
<h1>Cascading?</h1>

<h2>Cascading Wraps Hadoop</h2>

<h2>Cascalog Wraps Cascading</h2>

<!--- Notes:
What is Cascading? Cascading is a Java library that makes it easier to program
jobs for Hadoop. It takes the Hadoop Map/Reduce idea and layers a data flow
abstraction on top of it. You create data source called taps, allow the data
to flow through many different transforms or combinations, and then at the end
the data flows into a sink. This abstraction can make many Map/Reduce jobs easier
to program, and has many followers.
--->
</div>
      <div class='step' >
    
<h1>Datalog?</h1>

<!--- Notes:
Datalog is a logic programming language designed to query data. It is similar to
Prolog, but with a couple of tweaks to make it better behaved. For instance, all
Datalog queries are guaranteed to terminate when run on finite datasets. Datalog,
like most logic programming languages, lets you program declaratively. Instead
of telling Cascalog how to do things, you tell it what you want at the end, and
Cascalog figures out how to do it.
--->
</div>
      <div class='step' >
    
<h1>Logic Programming?</h1>

<p>(in core.logic)</p>

<!--- Notes:
Cascalog may be the first time some of you have actually used logic programming.
Clojure has a library called core.logic which enables logic programming in
Clojure. Core.logic and cascalog are not the same, and neither uses the other,
but they share many of the same concepts. I'll explain the concepts first using
core.logic, and then in Cascalog so you can see the difference.

Declarative programming can be a difficult transition for many programmers. Years
of telling the computer exactly what to do have trained you to care about the
details of how. Declarative programming asks you to relax a little, and trust
the computer. When it works, it can be a great time saver. When something goes
wrong, it can be difficult to tell where the problem is.

For each line in the logic program, even if the other variables aren't
mentioned, they still exist. Filtering or adding an element will affect the entire
row. Picturing the rest of the members as ghosts over to the side might be helpful.
--->
</div>
      <div class='step' >
    
<h1>Facts/Relations</h1>
<pre><code class='prettyprint '>(defrel
      person first-name last-name  role)
(fact person "Dr."      "Horrible" :villain)
(fact person "Bad"      "Horse"    :villain)
(fact person "Captain"  "Hammer"   :hero)
(fact person "Penny"    ""         :bystander)
</code></pre></div>
      <div class='step' >
    
<h1>Logic Variables</h1>

<h2>For Physicists</h2>

<ul>
<li>Logic Variables abide by the Quantum Superposition principle</li>
<li>run* causes (repeated) wave function collapses</li>
<li>Don&#39;t use classical reasoning in quantum contexts!</li>
</ul>
</div>
      <div class='step' >
    
<h1>Logic Variables</h1>
<pre><code class='prettyprint '>(defrel person name)
(fact person "Dr. Horrible")
(fact person "Penny")
(fact person "Captain Hammer")

(run* [variable]
  (person variable))

;; output:
("Captain Hammer" "Penny" "Dr. Horrible")
</code></pre></div>
      <div class='step' >
    
<h1>Predicates</h1>
<pre><code class='prettyprint '>(defrel likes liker likee)
(fact likes "Dr. Horrible" "Penny")
(fact likes "Penny" "Captain Hammer")
(fact likes "Captain Hammer" "Captain Hammer")

;; Who likes Penny?
(run* [q]
  (likes q "Penny"))

;; output:
("Dr. Horrible")

;; Any pairs that like each other?
(run* [q]
  (fresh [x y]
    (== q [x y])
    (likes x y)
    (likes y x)))

;; output:
(["Captain Hammer" "Captain Hammer"])
</code></pre></div>
      <div class='step' >
    
<h1>Cascalog</h1>

<ul>
<li>(not= core.logic Datalog)</li>
<li>Tuple all the things</li>
</ul>

<!--- Notes:
Cascalog and core.logic are not the same. Although they both embrace the logic
programming paradigm, you won't be able to copy code from one to the other.
--->
</div>
      <div class='step' >
    
<h1>Cascalog</h1>

<ul>
<li>Generators - Tuple source</li>
<li>Operations - Augment or filter tuples</li>
<li>Aggregators - Act on sequences of tuples</li>
</ul>
</div>
      <div class='step' >
    
<h1>Generators</h1>

<p>Vector source:</p>
<pre><code class='prettyprint '>(def people [
 [ "Dr."      "Horrible" :villain   ]
 [ "Bad"      "Horse"    :villain   ]
 [ "Captain"  "Hammer"   :hero      ]
 [ "Penny"    ""         :bystander ]])
</code></pre>
<p>TSV source (using a tap):</p>
<pre><code class='prettyprint '>Dr.     Horrible villain
Bad     Horse    villain
Captain Hammer   hero
Penny            bystander
</code></pre><pre><code class='prettyprint '>(defn split
  [^String sentence]
  (.split sentence "\\t"))

(def people
  (<- [?fname ?lname ?role]
    (lfs-textline "people.tsv" ?line)
    (split ?line :> ?fname ?lname ?role)))
</code></pre></div>
      <div class='step' >
    
<h1>Taps</h1>

<ul>
<li>lfs-textline</li>
</ul>
<pre><code class='prettyprint '>((lfs-textline "/home/alexr/resolve-ml/inputs") ?input-line)
</code></pre>
<ul>
<li>hfs-textline - Read (or write) inputs from HDFS</li>
<li>hfs-seqfile - Read (or write) hadoop seqfiles</li>
</ul>

<p>You can write:</p>

<ul>
<li>Taps that read/write JSON</li>
<li>Taps that read/write protobufs</li>
</ul>
</div>
      <div class='step' >
    
<h1>Queries</h1>

<p>Define a query.</p>
<pre><code class='prettyprint '>(def query
  (<- [?name ?age]
    (people ?name ?age)
    (< ?age 40)))
</code></pre>
<p>Execute the query.</p>
<pre><code class='prettyprint '>(?- (lfs-textline "/home/alexr/output-path")
  query)
</code></pre>
<p>Define and execute the query.</p>
<pre><code class='prettyprint '>(??<- [?name ?age]
  (people ?name ?age)
  (< ?age 40))
</code></pre></div>
      <div class='step' >
    
<h1>Operations</h1>
<pre><code class='prettyprint '>(def people [
 ["Dr."      "Horrible" :villain  ]
 ["Bad"      "Horse"    :villain  ]
 ["Captain"  "Hammer"   :hero     ]
 ["Penny"    ""         :bystander]])

;; Filter:
(??<- [?fname]
  (people ?fname ?lname _)
  (clojure.string/blank? ?lname))

;output
(["Penny"])

;; Augment
(defn expand-abbreviations [name]
  (if (= name "Dr.") "Doctor" name))

(??<- [?fname ?lname]
  (people ?orig-fname ?lname :villain) ; Filter, only villains
  (expand-abbreviations ?orig-fname :> ?fname))

;ouput
(["Doctor" "Horrible"] ["Bad Horse"])
</code></pre></div>
      <div class='step' >
    
<h1>Joins</h1>
<pre><code class='prettyprint '>(def people [
 ["Dr. Horrible"   :villain  ]
 ["Bad Horse"      :villain  ]
 ["Captain Hammer" :hero     ]
 ["Penny"          :bystander]])

(def likes [
 ["Dr. Horrible"   "Penny"         ]
 ["Penny"          "Captain Hammer"]
 ["Captain Hammer" "Captain Hammer"]])

(def favorite-foods [
 ["Penny" "Frozen yogurt"]])

;; What people are liked by villains, and what food do they like?
(??<- [?liked-person ?food]
  (people ?liker :villain) ; filtering!
  (likes ?liker ?liked-person)
  (favorite-foods ?liked-person ?food))

;output
(["Penny" "Frozen yogurt"])
</code></pre>
<p>Painless join across three sources!</p>
</div>
      <div class='step' >
    
<h1>Aggregators</h1>
<pre><code class='prettyprint '>(def people [
 ["Dr. Horrible"   :villain  ]
 ["Bad Horse"      :villain  ]
 ["Captain Hammer" :hero     ]
 ["Penny"          :bystander]])

; How many of each role are there?
(??<- [?role ?count]
  (people _ ?role)
  (cascalog.ops/count ?count))

;output
([:villain 2] [:hero 1] [:bystander 1])
</code></pre></div>
      <div class='step' >
    
<h1>Demo</h1>
</div>
      <div class='step' >
    
<p>Please don&#39;t take any of the conclusions from the demo seriously.</p>
</div>
      <div class='step' >
    
<h1>Cascalog at Factual</h1>
</div>
      <div class='step' >
    
<h1>Thanks</h1>

<p>Nathan Marz (and others) for Cascalog</p>

<p>Rich Hickey for Clojure</p>

<p>Alex Miller for Clojure/West</p>
</div>
      <div class='step' >
    
<h1>Cascalog</h1>

<h2>Logic Programming Over Hadoop</h2>

<p>Alex Robbins</p>

<ul>
<li><a href="mailto:alexr@factual.com">alexr@factual.com</a> &nbsp;&nbsp;&nbsp;&nbsp; <img src="images/factual-high-res.png" alt="factual-logo" title="Factual"></li>
<li><a href="mailto:alexander.j.robbins@gmail.com">alexander.j.robbins@gmail.com</a></li>
<li><a href="https://github.com/alexrobbins/cascalog-intro">https://github.com/alexrobbins/cascalog-intro</a></li>
</ul>

<p>Factual is hiring!</p>

      </div>
    <script src="js/impress.js"></script>
    <script>impress().init();</script>
  </body>
</html>
    